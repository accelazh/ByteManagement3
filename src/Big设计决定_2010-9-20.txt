1. Itr接口均统一改成java.util.Iterator模式
2. HashMap设计思想总结：
	1. 版本的概念：hashMap每次扩增，产生一个具有新的大小的哈希表，称作一个新的版本，
	        同一个版本，其表大小保持不变。在新旧哈希表元素搬迁、哈希表扩张等上，使用版本
	        的概念管理不同大小的表的共存，更加容易。
	2. 有了版本的概念，哈系表的一系列扩张，就可以看作是不断加入新的版本。各个版本组成
	        了一个版本队列。
	3. 使用非阻塞的方式加入新版本，维持多个不同版本，可以创造高并发的哈希表扩张策略。
	        但是元素搬迁、扩张、新表初始化、哈希表的正常操作（put/get等），之间的并发管理
	       会变得非常困难。
	4. 仅仅维持最新的两个版本（旧的那个，正在把元素相新的搬迁）。哈希表扩张，新建版本，
	       初始化，在分隔开的流程里完成，与哈希表的put/get系列操作、搬迁操作隔离。当新版本
	       初始化完成，再在全局读写锁的锁定下，原子性地入队到当前正在使用的版本队列上。这是
	      我目前采用的设计。其中，因为增加新版本时，全局读写锁排除了所有其它正在进行的操作，
	      并发控制变得相当容易。
	5. 不需初始化的元素搬迁方法。哈希表扩张后，新的区域一般是需要初始化为null的。但是这
	     个元素搬迁方法可以省去初始化步骤：搬迁时，初始化一格，然后再搬迁该格，然后移动到下
	     一格（哈希表的大小总是2的幂次，使得第k格的元素一定搬迁到第k格或者第k+2^n格）。put
	     操作进行时，根据搬迁进度进行相应操作。如果要put到未搬过的格，那么put到旧表，如果要
	    搬迁到搬过的格，那么put到新表。但是这个方法，在搬迁者和put之间的，并发控制会变得有
	    一定难度，实际情况没有上面说的这么简单。搬迁这和put之间会发生耦合，对于多线程解耦的
	    设计思想来说，麻烦多多。所以这个方法目前我也没采用。
	 6. 新旧版本置换中，用读写锁进行全局锁定，可以省去很多并发控制的麻烦。如果不这样，虽然
	 	非常诱人，但总是会引入n多并发控制的难题。
3. 重大设计变更：
	1. 持久化，Persistancer、PersistanceDelegate被证明是失败的设计（哈希表的复杂度使得
	它们很难用，构造函数中传入的许多参数，是应该放到持久化中还是构造函数中，难以取舍，等等）。
	根据AOP的思想，使用java对象流，才应该是上策
	2. Persistancer.read、PersistanceDelegate.read的容错性是多余的。这种容错性与程序的正常
	逻辑混合，使得难以编码。容错性应该由外界处理，使用冗余、校验码扥等机制。java对象流也使得
	上述的初始化函数的内置容错性多余了。
	2.5. 上面两条的思想就是，能够无关的东西，统统外置化。这是AOP的思想。
	3. clear方法仅删除元素，dispose才释放全部空间。dispose后，把类的关键成员变量置null，类不
	再可用。
4. HashMap的实现乱七八糟，应该再整理整理
5. BinaryPool的设计也许能够再净化，Block的几个变量的职责有点乱。
6. 整个项目来说BinaryPool的设计、SegmentArray的设计、ByteAccesser兼容内存、文件、swap、内存
        文件映射的设计，值得mark。尽管BinaryPool还有一些问题。
7. 2010-9-20项目冻结：
	1. 目前来看，该项目的准备知识还是不足。需要学习并发的更深层管理
	2. 已经设计出简单性、效率、并发都不错的哈希表了，只是还没有实现，实现挺麻烦
	3. 知识和经验已经到手，不需要继续投入时间了。现在有更重要的事要做，以后经过更深入的学习再来
	从新思考这个项目也更好。
